{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488805fb",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d77e869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# upload data\n",
    "df = pd.read_csv('datacopy.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7242b077",
   "metadata": {},
   "source": [
    "### Let's drop colums that we won't use, duplicates and NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "45b642b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop colums \"CodingActivities\", \"LearnCode\", \"LearnCodeOnline\", \"LearnCodeCoursesCert\", \"DevType\" <- (this one\n",
    "# will be too complicated to analise), \"PurchaseInfluence\", \"BuyNewTool\", \"LanguageWantToWorkWith\",\n",
    "# \"DatabaseHaveWorkedWith\", \"DatabaseWantToWorkWith\", \"PlatformHaveWorkedWith\", \"PlatformWantToWorkWith\", \n",
    "# \"WebframeHaveWorkedWith\", \"WebframeWantToWorkWith\", \"MiscTechHaveWorkedWith\", \"MiscTechWantToWorkWith\",\n",
    "# \"ToolsTechHaveWorkedWith\" <- (this one will be complicated to like split and analyse, but if we have \n",
    "# time, we can try), \"ToolsTechWantToWorkWith\", \"NEWCollabToolsHaveWorkedWith\", \"NEWCollabToolsWantToWorkWith\", \n",
    "# \"OpSysProfessional use\", \"OpSysPersonal use\", \"VersionControlSystem\", \"VCInteraction\", \"VCHostingPersonal use\",\n",
    "# \"VCHostingProfessional use\", \"OfficeStackAsyncHaveWorkedWith\", \"OfficeStackAsyncWantToWorkWith\", \n",
    "# \"OfficeStackSyncHaveWorkedWith\", \"OfficeStackSyncWantToWorkWith\", \"Blockchain\", \"NEWSOSites\", \"SOVisitFreq\", \n",
    "# \"SOAccount\", \"SOPartFreq\", \"SOComm\", \"TBranch\", \"ICorPM\", \"Knowledge_1\", \"Knowledge_2\", \"Knowledge_3\",\n",
    "# \"Knowledge_4\", \"Knowledge_5\", \"Knowledge_6\", \"Knowledge_7\", \"Frequency_1\", \"Frequency_2\", \"Frequency_3\", \n",
    "# \"TimeSearching\", \"TimeAnswering\", \"Onboarding\", \"ProfessionalTech\", \"TrueFalse_1\", TrueFalse_2\", TrueFalse_3\"\n",
    "# \"SurveyLength\", \"SurveyEase\", \"CompTotal\", \"CompFreq\", \"Currency\"\n",
    "\n",
    "df.drop(columns=[\"CodingActivities\", \"LearnCode\", \"LearnCodeOnline\", \"LearnCodeCoursesCert\", \"DevType\",\n",
    "                         \"PurchaseInfluence\", \"BuyNewTool\", \"LanguageWantToWorkWith\",\"DatabaseHaveWorkedWith\", \"DatabaseWantToWorkWith\", \"PlatformHaveWorkedWith\", \"PlatformWantToWorkWith\", \"WebframeHaveWorkedWith\", \"WebframeWantToWorkWith\", \"MiscTechHaveWorkedWith\", \"MiscTechWantToWorkWith\",\n",
    "                        \"ToolsTechHaveWorkedWith\",\"ToolsTechWantToWorkWith\", \"NEWCollabToolsHaveWorkedWith\",\n",
    "                        \"NEWCollabToolsWantToWorkWith\",\"OpSysProfessional use\", \"OpSysPersonal use\",\n",
    "                        \"VersionControlSystem\", \"VCInteraction\", \"VCHostingPersonal use\",\n",
    "                        \"VCHostingProfessional use\", \"OfficeStackAsyncHaveWorkedWith\", \"OfficeStackAsyncWantToWorkWith\",\n",
    "                        \"OfficeStackSyncHaveWorkedWith\", \"OfficeStackSyncWantToWorkWith\", \"Blockchain\", \"NEWSOSites\", \"SOVisitFreq\",\n",
    "                        \"SOAccount\", \"SOPartFreq\", \"SOComm\", \"TBranch\", \"ICorPM\", \"Knowledge_1\", \"Knowledge_2\", \"Knowledge_3\",\n",
    "                        \"Knowledge_4\", \"Knowledge_5\", \"Knowledge_6\", \"Knowledge_7\", \"Frequency_1\", \"Frequency_2\", \"Frequency_3\",\n",
    "                        \"TimeSearching\", \"TimeAnswering\", \"Onboarding\", \"ProfessionalTech\", \"TrueFalse_1\", \"TrueFalse_2\", \"TrueFalse_3\",\n",
    "                        \"SurveyLength\", \"SurveyEase\",\"CompTotal\", \"CompFreq\",\"Currency\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c5ecce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates if we have any(we don't)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fbc3eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing colums that contain at least one NaN value\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04e89f",
   "metadata": {},
   "source": [
    "### Replacing string values in the columns with numericals ones + desplaying inital unique values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ba3085dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainBranch:  ['I am not primarily a developer, but I write code sometimes as part of my work'\n",
      " 'I am a developer by profession']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in MainBranch column\n",
    "print('MainBranch: ', df['MainBranch'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6b5518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'MainBranch'] = pd.factorize(df['MainBranch'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2499b5b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainBranch:  [1 2]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in MainBranch column\n",
    "print('MainBranch: ', df['MainBranch'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3d43db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment:  ['Employed, full-time;Independent contractor, freelancer, or self-employed'\n",
      " 'Employed, full-time'\n",
      " 'Independent contractor, freelancer, or self-employed'\n",
      " 'Employed, part-time' 'Employed, full-time;Employed, part-time'\n",
      " 'Independent contractor, freelancer, or self-employed;Employed, part-time'\n",
      " 'Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time'\n",
      " 'Employed, part-time;Retired' 'Employed, full-time;Retired'\n",
      " 'Employed, full-time;Independent contractor, freelancer, or self-employed;Retired']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in MainBranch column\n",
    "print('Employment: ', df['Employment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0d2fb1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Employment'] = pd.factorize(df['Employment'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d5c7c014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment:  [1 2 3 4 5 6 7 8 9 10]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in MainBranch column\n",
    "print('Employment: ', df['Employment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7cce958b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoteWork:  ['Fully remote' 'Hybrid (some remote, some in-person)' 'Full in-person']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'RemoteWork' column\n",
    "print('RemoteWork: ', df['RemoteWork'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ed3e657d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'RemoteWork'] = pd.factorize(df['RemoteWork'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "42797af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoteWork:  [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'RemoteWork' column\n",
    "print('RemoteWork: ', df['RemoteWork'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cb08287d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdLevel:  ['Bachelor’s degree (B.A., B.S., B.Eng., etc.)'\n",
      " 'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)' 'Something else'\n",
      " 'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)'\n",
      " 'Some college/university study without earning a degree'\n",
      " 'Other doctoral degree (Ph.D., Ed.D., etc.)'\n",
      " 'Associate degree (A.A., A.S., etc.)' 'Primary/elementary school'\n",
      " 'Professional degree (JD, MD, etc.)']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'EdLevel' column\n",
    "print('EdLevel: ', df['EdLevel'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e96c917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'EdLevel'] = pd.factorize(df['EdLevel'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "89e95660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdLevel:  [1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'EdLevel' column\n",
    "print('EdLevel: ', df['EdLevel'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a217db88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsCode:  ['12' '11' '5' '25' '16' '20' '27' '24' '6' '3' '4' '40' '7' '9' '17' '10'\n",
      " '29' '13' '30' '26' '32' '14' '15' '8' '28' '19' '23' '48' '38' '21' '18'\n",
      " '22' '43' '31' '35' '39' '2' '42' '1' '45' '33' 'Less than 1 year' '34'\n",
      " '36' '37' '41' '44' 'More than 50 years' '46' '47' '50' '49']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'YearsCode' column\n",
    "print('YearsCode: ', df['YearsCode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "caca9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's group all year of code into 5 groups: less than 5 year, from 5 to 10, from 11 to 20, from 21 to 40 \n",
    "# and more than 40\n",
    "\n",
    "def process_age(age):\n",
    "    if age == 'Less than 1 year':\n",
    "        return 1\n",
    "    elif age == 'More than 50 years':\n",
    "        return (5)\n",
    "    age = int(age)\n",
    "    if age <5:\n",
    "        return(1)\n",
    "    elif (age >= 5 and age <=10):\n",
    "        return(2)\n",
    "    elif (age>10 and age <=20):\n",
    "        return (3)\n",
    "    elif (age>20 and age <=40):\n",
    "        return (4)\n",
    "    else:\n",
    "        return(5)\n",
    "\n",
    "# Apply the function to the column and create a new column\n",
    "df.loc[:,'YearsCode'] = df['YearsCode'].apply(process_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "afba972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsCode:  [3 2 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "print('YearsCode: ', df['YearsCode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "69534dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country:  ['United States of America' 'Italy' 'Canada' 'Germany' 'Ireland' 'Poland'\n",
      " 'Israel' 'Madagascar' 'Norway' 'Netherlands' 'Brazil' 'France' 'Uruguay'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Spain' 'Sweden'\n",
      " 'Romania' 'India' 'Greece' 'Portugal' 'Czech Republic' 'Kenya' 'Latvia'\n",
      " 'Austria' 'South Africa' 'China' 'Slovakia' 'Denmark' 'Australia'\n",
      " 'Viet Nam' 'Finland' 'Argentina' 'Hungary' 'Tunisia' 'Switzerland'\n",
      " 'Bangladesh' 'Ukraine' 'Maldives' 'Thailand' 'Hong Kong (S.A.R.)'\n",
      " 'Mexico' 'Serbia' 'Belgium' 'Egypt' 'Croatia' 'Russian Federation'\n",
      " 'Bosnia and Herzegovina' 'Armenia' 'Iran, Islamic Republic of...'\n",
      " 'Turkey' 'Belarus' 'Costa Rica' 'Estonia' 'Kazakhstan' 'Morocco'\n",
      " 'New Zealand' 'Ecuador' 'Bulgaria' 'Japan' 'Peru' 'Philippines'\n",
      " 'Indonesia' 'Republic of Korea' 'Colombia' 'Lebanon' 'Pakistan'\n",
      " 'Guatemala' 'Chile' 'Nepal' 'Jordan' 'Azerbaijan' 'Sri Lanka'\n",
      " 'United Arab Emirates' 'Singapore' 'South Korea' 'Lithuania' 'Taiwan'\n",
      " 'Saudi Arabia' 'Slovenia' 'Nigeria' 'Malaysia' 'Ethiopia' 'Cyprus'\n",
      " 'Andorra' 'Luxembourg' 'The former Yugoslav Republic of Macedonia'\n",
      " 'Syrian Arab Republic' 'Montenegro' 'Cambodia' 'Fiji' 'Mongolia'\n",
      " 'Tajikistan' 'Timor-Leste' 'Afghanistan' 'United Republic of Tanzania'\n",
      " 'Ghana' 'Cameroon' 'Kosovo' 'Turkmenistan' 'Republic of Moldova'\n",
      " 'Botswana' 'Albania' 'Myanmar' 'Georgia' 'Dominican Republic' 'Rwanda'\n",
      " 'Malta' 'Venezuela, Bolivarian Republic of...' 'El Salvador' 'Bolivia'\n",
      " 'Isle of Man' 'Algeria' 'Mali' 'Panama'\n",
      " \"Lao People's Democratic Republic\" 'Iceland' 'Honduras' 'Bahrain'\n",
      " 'Paraguay' 'Cuba' 'Democratic Republic of the Congo' \"Côte d'Ivoire\"\n",
      " 'Uganda' 'Mauritius' 'Nicaragua' 'Uzbekistan' 'Iraq' 'Kyrgyzstan'\n",
      " 'Mozambique' 'Kuwait' 'Libyan Arab Jamahiriya' 'Angola' 'Nomadic' 'Oman'\n",
      " 'Sudan' 'Palestine' 'Zambia' 'Somalia' 'Guinea' 'Zimbabwe' 'Cape Verde'\n",
      " 'Senegal' 'Trinidad and Tobago' 'Benin' 'Bhutan' 'Togo' 'Suriname'\n",
      " 'Jamaica' 'Yemen' 'Malawi' 'Qatar' 'Guyana' 'Congo, Republic of the...'\n",
      " 'Saint Lucia' 'Seychelles']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Country' column\n",
    "print('Country: ', df['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8a6aa57f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'Country'] = pd.factorize(df['Country'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ecd740dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country:  [1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75\n",
      " 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153\n",
      " 154 155]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Country' column\n",
    "print('Country: ', df['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fe393360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrgSize:  ['20 to 99 employees' '2 to 9 employees' '5,000 to 9,999 employees'\n",
      " '100 to 499 employees' '10,000 or more employees'\n",
      " 'Just me - I am a freelancer, sole proprietor, etc.'\n",
      " '500 to 999 employees' '1,000 to 4,999 employees' '10 to 19 employees'\n",
      " 'I don’t know']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'OrgSize' column\n",
    "print('OrgSize: ', df['OrgSize'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bd5eb803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'OrgSize'] = pd.factorize(df['OrgSize'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "729abacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrgSize:  [1 2 3 4 5 6 7 8 9 10]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'OrgSize' column\n",
    "print('OrgSize: ', df['OrgSize'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e982063d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age:  ['35-44 years old' '25-34 years old' '45-54 years old' '55-64 years old'\n",
      " '18-24 years old' '65 years or older' 'Prefer not to say'\n",
      " 'Under 18 years old']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Age' column\n",
    "print('Age: ', df['Age'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6a3c7047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'Age'] = pd.factorize(df['Age'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "63cae5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age:  [1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Age' column\n",
    "print('Age: ', df['Age'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0840dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  ['Man' 'Woman' 'Prefer not to say'\n",
      " 'Non-binary, genderqueer, or gender non-conforming'\n",
      " 'Or, in your own words:'\n",
      " 'Or, in your own words:;Non-binary, genderqueer, or gender non-conforming'\n",
      " 'Woman;Non-binary, genderqueer, or gender non-conforming'\n",
      " 'Man;Non-binary, genderqueer, or gender non-conforming'\n",
      " 'Man;Or, in your own words:'\n",
      " 'Or, in your own words:;Woman;Non-binary, genderqueer, or gender non-conforming'\n",
      " 'Man;Woman;Non-binary, genderqueer, or gender non-conforming'\n",
      " 'Man;Or, in your own words:;Woman;Non-binary, genderqueer, or gender non-conforming'\n",
      " 'Man;Or, in your own words:;Non-binary, genderqueer, or gender non-conforming'\n",
      " 'Man;Woman']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Gender' column\n",
    "print('Gender: ', df['Gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "90006d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Gender'] = pd.factorize(df['Gender'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2cd91717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  [1 2 3 4 5 6 7 8 9 10 11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Gender' column\n",
    "print('Gender: ', df['Gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3eb258e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trans:  ['No' 'Prefer not to say' 'Yes' 'Or, in your own words:']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Trans' column\n",
    "print('Trans: ', df['Trans'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "121d61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Trans'] = pd.factorize(df['Trans'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c3b98858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trans:  [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Trans' column\n",
    "print('Trans: ', df['Trans'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bd491745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sexuality:  ['Straight / Heterosexual' 'Prefer not to say' 'Gay or Lesbian' 'Bisexual'\n",
      " 'Bisexual;Straight / Heterosexual' 'Queer' 'Prefer to self-describe:'\n",
      " 'Bisexual;Queer' 'Gay or Lesbian;Queer'\n",
      " 'Bisexual;Prefer to self-describe:'\n",
      " 'Straight / Heterosexual;Prefer to self-describe:'\n",
      " 'Bisexual;Gay or Lesbian;Queer' 'Bisexual;Prefer to self-describe:;Queer'\n",
      " 'Straight / Heterosexual;Queer'\n",
      " 'Bisexual;Prefer to self-describe:;Gay or Lesbian'\n",
      " 'Bisexual;Straight / Heterosexual;Prefer to self-describe:'\n",
      " 'Bisexual;Gay or Lesbian' 'Prefer to self-describe:;Queer'\n",
      " 'Bisexual;Straight / Heterosexual;Gay or Lesbian'\n",
      " 'Prefer to self-describe:;Gay or Lesbian'\n",
      " 'Bisexual;Straight / Heterosexual;Queer'\n",
      " 'Bisexual;Straight / Heterosexual;Gay or Lesbian;Queer'\n",
      " 'Straight / Heterosexual;Gay or Lesbian'\n",
      " 'Prefer to self-describe:;Gay or Lesbian;Queer'\n",
      " 'Straight / Heterosexual;Prefer to self-describe:;Queer'\n",
      " 'Bisexual;Straight / Heterosexual;Prefer to self-describe:;Gay or Lesbian;Queer']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Sexuality' column\n",
    "print('Sexuality: ', df['Sexuality'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "35353961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Sexuality'] = pd.factorize(df['Sexuality'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9580d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicity:  ['White' 'European' 'White;North American' 'White;European'\n",
      " 'Prefer not to say' 'Middle Eastern' 'African'\n",
      " 'White;European;Asian;East Asian' 'Black;Caribbean'\n",
      " 'Hispanic or Latino/a' 'European;African' 'White;Hispanic or Latino/a'\n",
      " 'European;Hispanic or Latino/a' 'White;European;Middle Eastern'\n",
      " 'East Asian' 'Or, in your own words:'\n",
      " 'White;Hispanic or Latino/a;South American' 'Indian;Asian'\n",
      " 'Asian;South Asian' 'Indian' 'White;European;Hispanic or Latino/a'\n",
      " 'North American' 'Or, in your own words:;Ethnoreligious group'\n",
      " 'African;Black'\n",
      " 'White;European;North American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Middle Eastern;Hispanic or Latino/a;South American'\n",
      " 'European;Hispanic or Latino/a;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;North American' 'White;Or, in your own words:'\n",
      " 'White;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'White;European;Middle Eastern;Asian;Multiracial;Biracial'\n",
      " 'White;European;North American' 'White;Asian;Multiracial'\n",
      " 'European;Asian' 'South American' 'Asian;Southeast Asian' 'Biracial'\n",
      " 'White;Asian' 'North African' 'Asian' 'Multiracial'\n",
      " 'Asian;Southeast Asian;South Asian' 'Indian;Asian;South Asian'\n",
      " 'Southeast Asian' 'White;Or, in your own words:;North American'\n",
      " 'Ethnoreligious group' 'South American;Multiracial' 'Indian;South Asian'\n",
      " 'Middle Eastern;Asian' 'Middle Eastern;African' 'South Asian'\n",
      " 'White;Middle Eastern' 'White;Asian;Multiracial;Biracial'\n",
      " 'White;Asian;Biracial' 'Indian;North American' 'Black' 'White;East Asian'\n",
      " 'European;Caribbean;Multiracial' 'Central American;Hispanic or Latino/a'\n",
      " 'White;South Asian;Multiracial' 'White;Southeast Asian;Biracial'\n",
      " 'White;Biracial' 'European;Black'\n",
      " 'White;European;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'North American;Asian;Biracial' \"I don't know\"\n",
      " 'White;Ethnoreligious group;East Asian;Biracial' 'African;North African'\n",
      " 'White;African' 'White;South American' 'European;Middle Eastern'\n",
      " 'North American;Multiracial;Biracial'\n",
      " 'White;Asian;Southeast Asian;Biracial'\n",
      " 'White;Indian;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;Middle Eastern;Ethnoreligious group'\n",
      " 'White;European;Hispanic or Latino/a;Multiracial' 'Caribbean'\n",
      " 'East Asian;South American' 'Asian;East Asian'\n",
      " 'White;North American;South American' 'White;Ethnoreligious group'\n",
      " 'White;Southeast Asian' 'Indian;European;Asian;Multiracial'\n",
      " 'White;European;North American;Middle Eastern;Multiracial'\n",
      " 'White;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Black;Multiracial;Biracial'\n",
      " 'European;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'European;Biracial;Pacific Islander'\n",
      " 'White;North American;Asian;East Asian;Multiracial'\n",
      " 'White;Indian;European;Biracial' 'Indian;Middle Eastern;South Asian'\n",
      " 'White;Or, in your own words:;European' 'White;Black;Caribbean'\n",
      " 'White;Indian;Multiracial;Biracial' 'Central Asian' 'White;Multiracial'\n",
      " 'European;Multiracial;Pacific Islander'\n",
      " 'Black;Hispanic or Latino/a;Multiracial'\n",
      " 'Asian;East Asian;Southeast Asian' 'White;Black'\n",
      " 'Or, in your own words:;Middle Eastern;African'\n",
      " 'North American;Asian;East Asian' 'Hispanic or Latino/a;Multiracial'\n",
      " 'White;Indian;North American'\n",
      " 'White;North American;Hispanic or Latino/a;South American'\n",
      " 'Middle Eastern;Asian;Multiracial;Biracial' 'Central American'\n",
      " 'Hispanic or Latino/a;South American' 'Or, in your own words:;Asian'\n",
      " 'White;Hispanic or Latino/a;Biracial' 'European;African;Biracial'\n",
      " 'White;North American;Hispanic or Latino/a;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Indian;Middle Eastern' 'White;European;Ethnoreligious group'\n",
      " 'White;Middle Eastern;Asian;East Asian;Central Asian'\n",
      " 'Indian;Asian;Southeast Asian' 'East Asian;Biracial'\n",
      " 'Or, in your own words:;Hispanic or Latino/a;South American'\n",
      " 'White;Indian;European;North American;Middle Eastern;Ethnoreligious group;African;Asian;East Asian;Black;Caribbean;Southeast Asian;Central American;North African;Hispanic or Latino/a;South American;South Asian;Multiracial;Biracial;Indigenous (such as Native American or Indigenous Australian);Pacific Islander;Central Asian'\n",
      " 'Or, in your own words:;European' 'Black;Caribbean;Multiracial'\n",
      " 'Middle Eastern;Asian;Central Asian' 'White;European;Asian'\n",
      " 'Or, in your own words:;Southeast Asian' 'Asian;East Asian;Central Asian'\n",
      " 'Asian;East Asian;Multiracial'\n",
      " 'White;Ethnoreligious group;South American' 'Indian;Middle Eastern;Asian'\n",
      " 'White;African;North African'\n",
      " 'European;North American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Middle Eastern;African;Multiracial'\n",
      " 'White;European;Middle Eastern;North African;Multiracial'\n",
      " 'White;North African' 'Indian;European'\n",
      " 'Hispanic or Latino/a;South American;Multiracial'\n",
      " 'Middle Eastern;South Asian' 'White;Middle Eastern;North African'\n",
      " 'European;Middle Eastern;Central Asian'\n",
      " 'European;Middle Eastern;Biracial' 'White;European;South Asian;Biracial'\n",
      " 'White;European;Asian;Multiracial' 'White;Middle Eastern;Central Asian'\n",
      " 'Or, in your own words:;Asian;South Asian' 'European;Central Asian'\n",
      " 'White;Middle Eastern;Asian' 'Pacific Islander'\n",
      " 'White;European;Multiracial' 'White;Middle Eastern;Multiracial'\n",
      " 'Or, in your own words:;European;Middle Eastern'\n",
      " 'European;South American' 'Indian;Southeast Asian;South Asian'\n",
      " 'Southeast Asian;South Asian' 'Asian;Multiracial'\n",
      " 'White;North American;East Asian;Biracial' 'Middle Eastern;North African'\n",
      " 'European;Biracial' 'White;Indian' 'North American;Hispanic or Latino/a'\n",
      " 'White;North American;Middle Eastern;North African'\n",
      " 'Middle Eastern;Multiracial'\n",
      " 'North American;Middle Eastern;Hispanic or Latino/a;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Pacific Islander' 'Caribbean;Hispanic or Latino/a'\n",
      " 'European;North African;Biracial'\n",
      " 'Or, in your own words:;Middle Eastern;Multiracial'\n",
      " 'Asian;Hispanic or Latino/a;Multiracial'\n",
      " 'White;Or, in your own words:;European;South American'\n",
      " 'Indian;Middle Eastern;Asian;South Asian'\n",
      " 'White;Hispanic or Latino/a;Multiracial'\n",
      " 'White;Caribbean;Hispanic or Latino/a' 'White;European;Asian;Biracial'\n",
      " 'White;European;South American' 'Black;Hispanic or Latino/a;Biracial'\n",
      " 'Indian;Caribbean;South American;South Asian' 'White;Caribbean;Biracial'\n",
      " 'White;Or, in your own words:;Hispanic or Latino/a;Multiracial'\n",
      " 'European;African;Hispanic or Latino/a'\n",
      " 'Indian;Asian;Southeast Asian;South Asian'\n",
      " 'White;European;North American;Middle Eastern'\n",
      " 'Black;Hispanic or Latino/a;South American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;Central American;Hispanic or Latino/a'\n",
      " 'African;North African;Multiracial'\n",
      " 'Hispanic or Latino/a;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;Central American'\n",
      " 'White;Or, in your own words:;European;Middle Eastern;Ethnoreligious group'\n",
      " 'Black;Hispanic or Latino/a' 'White;European;Biracial'\n",
      " 'White;European;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Middle Eastern;Biracial'\n",
      " 'White;Ethnoreligious group;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;African' 'White;Multiracial;Pacific Islander'\n",
      " 'White;Caribbean;Hispanic or Latino/a;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Asian;South Asian;Biracial' 'European;Asian;Multiracial;Biracial'\n",
      " 'European;Asian;East Asian' 'Asian;Southeast Asian;Multiracial'\n",
      " 'White;Multiracial;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Indian;Southeast Asian' 'European;African;Black;Multiracial;Biracial'\n",
      " 'Asian;Hispanic or Latino/a;Biracial'\n",
      " 'European;Middle Eastern;Hispanic or Latino/a;Multiracial'\n",
      " 'Asian;East Asian;Hispanic or Latino/a;Biracial'\n",
      " 'European;Southeast Asian' 'White;North American;Hispanic or Latino/a'\n",
      " 'White;European;Caribbean;Central American;Hispanic or Latino/a'\n",
      " 'White;Central American;Hispanic or Latino/a' 'Black;South American'\n",
      " 'Middle Eastern;Hispanic or Latino/a;Multiracial;Pacific Islander'\n",
      " 'North American;Asian;South American' 'White;European;Central Asian'\n",
      " 'White;North American;Black;Multiracial;Biracial'\n",
      " 'Or, in your own words:;Middle Eastern'\n",
      " 'North American;Central American;Hispanic or Latino/a;South American'\n",
      " 'North American;Middle Eastern;Hispanic or Latino/a'\n",
      " 'White;European;North American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Caribbean;Hispanic or Latino/a;South American'\n",
      " 'White;North American;Asian;East Asian;Multiracial;Biracial'\n",
      " 'White;European;Middle Eastern;Multiracial;Biracial;Central Asian'\n",
      " 'Black;South American;Multiracial'\n",
      " 'Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;Ethnoreligious group;Biracial;Central Asian'\n",
      " 'North American;Central American;Hispanic or Latino/a'\n",
      " 'Indian;European;Asian' 'White;Asian;Multiracial;Pacific Islander'\n",
      " 'Asian;Black;Southeast Asian;Biracial' 'North American;Asian;South Asian'\n",
      " 'White;European;South American;Multiracial'\n",
      " 'White;European;Hispanic or Latino/a;South American'\n",
      " 'White;North American;Caribbean' 'Asian;South American'\n",
      " 'North American;Middle Eastern;North African' 'White;Black;Biracial'\n",
      " 'White;Or, in your own words:;European;Middle Eastern;Ethnoreligious group;Multiracial'\n",
      " 'White;Caribbean' 'Or, in your own words:;Central Asian'\n",
      " 'Or, in your own words:;South Asian'\n",
      " 'White;European;Middle Eastern;Asian'\n",
      " 'White;East Asian;Multiracial;Pacific Islander'\n",
      " 'Biracial;Pacific Islander' 'White;South American;Multiracial'\n",
      " 'White;European;Hispanic or Latino/a;South American;Multiracial;Biracial'\n",
      " 'Or, in your own words:;African'\n",
      " 'White;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Middle Eastern;Southeast Asian;Biracial'\n",
      " 'Southeast Asian;Pacific Islander'\n",
      " 'White;Middle Eastern;Asian;Multiracial'\n",
      " 'Caribbean;Hispanic or Latino/a;Biracial'\n",
      " 'Indian;Asian;Hispanic or Latino/a'\n",
      " 'Indian;North American;South American'\n",
      " 'European;Hispanic or Latino/a;South American'\n",
      " 'White;European;Ethnoreligious group;Multiracial'\n",
      " 'European;East Asian;Biracial' 'Or, in your own words:;East Asian'\n",
      " 'Or, in your own words:;European;Hispanic or Latino/a'\n",
      " 'Middle Eastern;Southeast Asian' 'White;European;North African;Biracial'\n",
      " 'White;European;Middle Eastern;Central Asian' 'European;Multiracial'\n",
      " 'East Asian;Southeast Asian'\n",
      " 'White;European;East Asian;Multiracial;Biracial'\n",
      " 'White;European;Middle Eastern;Biracial'\n",
      " 'European;Multiracial;Central Asian'\n",
      " 'North American;South American;Central Asian' 'Indian;European;Biracial'\n",
      " 'Indian;Asian;East Asian;Biracial' 'Middle Eastern;Ethnoreligious group'\n",
      " 'Hispanic or Latino/a;South American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;North American;Multiracial;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Asian;Southeast Asian;Multiracial;Biracial'\n",
      " 'White;Or, in your own words:;African;Hispanic or Latino/a;South American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;Central American;Biracial'\n",
      " 'White;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;North American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'North American;Central American'\n",
      " 'White;Caribbean;Central American;Hispanic or Latino/a'\n",
      " 'European;North American;Hispanic or Latino/a'\n",
      " 'Black;Hispanic or Latino/a;South American' 'Black;Biracial'\n",
      " 'Black;South American;Multiracial;Biracial'\n",
      " 'Or, in your own words:;European;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;Pacific Islander'\n",
      " 'European;Asian;Hispanic or Latino/a;Multiracial'\n",
      " 'Indian;Asian;Central Asian' 'Or, in your own words:;Indian'\n",
      " 'European;Hispanic or Latino/a;Multiracial;Biracial'\n",
      " 'European;Hispanic or Latino/a;Biracial'\n",
      " 'White;Or, in your own words:;European;Middle Eastern'\n",
      " 'Middle Eastern;African;North African' 'European;Black;Caribbean'\n",
      " 'Or, in your own words:;Middle Eastern;Ethnoreligious group'\n",
      " 'Caribbean;Hispanic or Latino/a;Multiracial'\n",
      " 'Caribbean;Central American;Hispanic or Latino/a'\n",
      " 'Hispanic or Latino/a;South American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;East Asian;South American;Biracial' 'Asian;Central Asian'\n",
      " 'African;Biracial' 'White;Middle Eastern;East Asian'\n",
      " 'Southeast Asian;Multiracial;Biracial'\n",
      " 'Middle Eastern;Asian;Southeast Asian'\n",
      " 'Hispanic or Latino/a;South American;Multiracial;Biracial'\n",
      " 'White;Central Asian'\n",
      " 'Asian;East Asian;Southeast Asian;South Asian;Multiracial;Central Asian'\n",
      " 'White;Asian;East Asian;Biracial'\n",
      " 'European;Hispanic or Latino/a;Multiracial'\n",
      " 'White;Or, in your own words:;Middle Eastern'\n",
      " 'White;European;Asian;Multiracial;Central Asian'\n",
      " 'Or, in your own words:;Caribbean;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'White;Middle Eastern;Ethnoreligious group' 'European;North African'\n",
      " 'Middle Eastern;Asian;East Asian'\n",
      " 'White;European;African;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Middle Eastern;African;Black'\n",
      " 'European;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Or, in your own words:;Pacific Islander'\n",
      " 'Hispanic or Latino/a;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Black;Caribbean;Hispanic or Latino/a'\n",
      " 'European;Black;Multiracial;Biracial' 'European;Middle Eastern;African'\n",
      " 'White;Middle Eastern;African'\n",
      " 'Asian;East Asian;Southeast Asian;Biracial' 'European;Black;Biracial'\n",
      " 'Asian;Black;South Asian' 'Or, in your own words:;European;Asian'\n",
      " 'European;North American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'North American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;North American;Middle Eastern' 'North American;Black'\n",
      " 'Or, in your own words:;North American;Asian;South American;Multiracial;Biracial'\n",
      " 'North American;Middle Eastern'\n",
      " 'White;European;Black;Hispanic or Latino/a;South American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Multiracial;Indigenous (such as Native American or Indigenous Australian);Pacific Islander'\n",
      " 'Southeast Asian;Multiracial'\n",
      " 'Asian;East Asian;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Or, in your own words:;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Or, in your own words:;Black;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;North American;Asian' 'Or, in your own words:;Asian;East Asian'\n",
      " 'White;Indian;European;Middle Eastern;Multiracial'\n",
      " 'European;Middle Eastern;Ethnoreligious group'\n",
      " 'Asian;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;Asian;Biracial'\n",
      " 'White;Or, in your own words:;European;Ethnoreligious group'\n",
      " 'South American;Biracial'\n",
      " 'White;African;Black;Caribbean;Multiracial;Biracial'\n",
      " 'Multiracial;Biracial' 'White;European;Middle Eastern;Multiracial'\n",
      " 'Black;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Asian;Pacific Islander'\n",
      " 'White;Ethnoreligious group;Hispanic or Latino/a'\n",
      " 'White;European;Ethnoreligious group;Hispanic or Latino/a;South American'\n",
      " 'White;European;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'White;North American;Asian;Biracial' 'White;European;Caribbean'\n",
      " 'European;Southeast Asian;Biracial'\n",
      " 'White;European;Hispanic or Latino/a;South American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Or, in your own words:;South American'\n",
      " 'White;North American;Asian;Multiracial;Pacific Islander'\n",
      " 'White;North American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;Middle Eastern;South American' 'Caribbean;South American'\n",
      " 'White;North American;East Asian;Black;Multiracial'\n",
      " 'Middle Eastern;Hispanic or Latino/a'\n",
      " 'White;Caribbean;Hispanic or Latino/a;South American'\n",
      " 'European;Ethnoreligious group' 'Asian;Southeast Asian;Biracial'\n",
      " 'Central American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;North American;Middle Eastern;Ethnoreligious group;African;Asian;North African;Hispanic or Latino/a'\n",
      " 'Black;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'Central American;Hispanic or Latino/a;Multiracial'\n",
      " 'White;Or, in your own words:;Hispanic or Latino/a'\n",
      " 'White;North American;Ethnoreligious group'\n",
      " 'White;European;North American;Central American;Multiracial'\n",
      " 'Asian;Black;Biracial'\n",
      " 'White;Ethnoreligious group;Hispanic or Latino/a;Multiracial'\n",
      " 'White;North American;Biracial' 'White;Asian;East Asian'\n",
      " 'White;Middle Eastern;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Or, in your own words:;European;Biracial'\n",
      " 'European;Caribbean;Hispanic or Latino/a'\n",
      " 'White;European;Middle Eastern;Multiracial;Biracial'\n",
      " 'North American;Asian;East Asian;South Asian'\n",
      " 'Hispanic or Latino/a;Biracial' 'White;Indian;Multiracial'\n",
      " 'White;Black;Caribbean;South Asian;Biracial' 'White;Asian;South American'\n",
      " 'African;Caribbean;Hispanic or Latino/a'\n",
      " 'White;North American;Southeast Asian;Biracial' 'White;Black;Multiracial'\n",
      " 'Or, in your own words:;Hispanic or Latino/a'\n",
      " 'Black;Hispanic or Latino/a;South American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Asian;Hispanic or Latino/a' 'Southeast Asian;Biracial'\n",
      " 'European;North American;Multiracial' 'Asian;Black'\n",
      " 'Caribbean;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'White;Or, in your own words:;European;Multiracial'\n",
      " 'African;Black;Biracial' 'African;Multiracial' 'European;African;Black'\n",
      " 'European;East Asian' 'European;Middle Eastern;Asian'\n",
      " 'Or, in your own words:;African;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;North African;Multiracial'\n",
      " 'Indian;Middle Eastern;Asian;Black;South Asian'\n",
      " 'Indian;European;Multiracial;Biracial'\n",
      " 'Asian;East Asian;Southeast Asian;South Asian'\n",
      " 'White;European;Caribbean;Hispanic or Latino/a;Multiracial'\n",
      " 'European;Asian;Southeast Asian;Biracial'\n",
      " 'White;Black;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'Asian;Central American;Hispanic or Latino/a'\n",
      " 'European;East Asian;Hispanic or Latino/a'\n",
      " 'White;Asian;East Asian;Hispanic or Latino/a;Multiracial'\n",
      " 'White;North American;Caribbean;Hispanic or Latino/a'\n",
      " 'White;European;North American;Multiracial' 'North American;Asian'\n",
      " 'White;European;North American;Ethnoreligious group'\n",
      " 'White;Indian;North American;Biracial'\n",
      " 'Or, in your own words:;European;North American'\n",
      " 'White;Asian;East Asian;Multiracial;Biracial'\n",
      " 'White;Hispanic or Latino/a;Pacific Islander'\n",
      " 'Ethnoreligious group;Hispanic or Latino/a;Biracial'\n",
      " 'Black;Hispanic or Latino/a;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Hispanic or Latino/a;South American;Multiracial;Biracial'\n",
      " 'Indian;European;North American;Middle Eastern;Ethnoreligious group;African;Asian;East Asian;Black;Caribbean;Southeast Asian;Central American;North African;Hispanic or Latino/a;South American;South Asian;Multiracial;Biracial;Indigenous (such as Native American or Indigenous Australian);Pacific Islander;Central Asian'\n",
      " 'Indian;Black' 'African;Black;North African' 'European;Asian;Multiracial'\n",
      " 'White;European;Black;Caribbean;Biracial'\n",
      " 'Or, in your own words:;Biracial'\n",
      " 'White;Caribbean;Hispanic or Latino/a;Multiracial;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;East Asian;Multiracial'\n",
      " 'North American;Hispanic or Latino/a;Multiracial'\n",
      " 'White;Southeast Asian;Multiracial'\n",
      " 'European;Caribbean;Hispanic or Latino/a;Biracial'\n",
      " 'White;North American;Hispanic or Latino/a;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Or, in your own words:;European;Hispanic or Latino/a'\n",
      " 'European;Central American;Hispanic or Latino/a;Multiracial'\n",
      " 'Caribbean;Multiracial' 'South American;South Asian'\n",
      " 'White;European;North American;Middle Eastern;Asian;East Asian;Caribbean;Central American;Hispanic or Latino/a;Multiracial;Indigenous (such as Native American or Indigenous Australian);Pacific Islander'\n",
      " 'Indian;North American;South Asian'\n",
      " 'White;European;Asian;East Asian;Multiracial;Biracial'\n",
      " 'North American;Black;Multiracial;Biracial'\n",
      " 'Asian;Southeast Asian;Pacific Islander'\n",
      " 'North American;Black;Multiracial'\n",
      " 'European;Middle Eastern;Asian;Multiracial'\n",
      " 'Or, in your own words:;Asian;Pacific Islander'\n",
      " 'White;European;Central American' 'White;European;Southeast Asian'\n",
      " 'Indian;Multiracial'\n",
      " 'Indian;East Asian;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Indian;Asian' 'East Asian;Central Asian'\n",
      " 'South American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Middle Eastern;African;Biracial' 'White;East Asian;Multiracial'\n",
      " 'White;Or, in your own words:;European;Biracial'\n",
      " 'White;South American;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;Caribbean;Hispanic or Latino/a'\n",
      " 'White;African;Multiracial' 'White;Central American'\n",
      " 'White;Ethnoreligious group;Multiracial'\n",
      " 'White;Asian;East Asian;Multiracial'\n",
      " 'White;Or, in your own words:;European;North American;Hispanic or Latino/a'\n",
      " 'White;Central American;Hispanic or Latino/a;South American'\n",
      " 'White;European;North American;African;Black;Central American;Hispanic or Latino/a;South American;Multiracial;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;East Asian;Multiracial;Biracial'\n",
      " 'White;European;North American;Ethnoreligious group;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;Indian;European;Multiracial'\n",
      " 'Caribbean;Central American;Hispanic or Latino/a;Multiracial'\n",
      " 'Or, in your own words:;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'White;Or, in your own words:;Ethnoreligious group'\n",
      " 'Middle Eastern;South American;Multiracial' 'Indian;Central Asian'\n",
      " 'White;European;Hispanic or Latino/a;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;Caribbean;Central American;Hispanic or Latino/a;Multiracial'\n",
      " 'European;Central American;Hispanic or Latino/a'\n",
      " 'Or, in your own words:;Multiracial'\n",
      " 'African;Hispanic or Latino/a;Multiracial' 'Middle Eastern;Central Asian'\n",
      " 'Caribbean;Biracial'\n",
      " 'European;Black;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;Asian;Southeast Asian;Biracial'\n",
      " 'Ethnoreligious group;Black;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;North American;Multiracial'\n",
      " 'Hispanic or Latino/a;Biracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;Middle Eastern;Asian;Multiracial'\n",
      " 'White;European;North American;African;Caribbean;Multiracial'\n",
      " 'African;Asian;Black;Southeast Asian;Pacific Islander'\n",
      " 'White;Asian;South Asian'\n",
      " 'White;European;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'Asian;East Asian;South American;Multiracial'\n",
      " 'Asian;South Asian;Central Asian' 'North American;Black;Caribbean'\n",
      " 'European;South American;Biracial'\n",
      " 'Or, in your own words:;Asian;Southeast Asian;South Asian'\n",
      " 'White;East Asian;Biracial'\n",
      " 'White;European;Hispanic or Latino/a;Biracial'\n",
      " 'European;North American;African;Black;Biracial'\n",
      " 'Asian;Central American;Hispanic or Latino/a;Multiracial'\n",
      " 'Caribbean;Central American;South American'\n",
      " 'White;Asian;Southeast Asian;South Asian;Multiracial;Biracial'\n",
      " 'Middle Eastern;East Asian' 'White;Or, in your own words:;European;Asian'\n",
      " 'Asian;East Asian;Pacific Islander'\n",
      " 'White;European;Multiracial;Central Asian'\n",
      " 'Or, in your own words:;Indian;Ethnoreligious group;Asian'\n",
      " 'European;Caribbean;Hispanic or Latino/a;South American'\n",
      " 'Indian;Asian;Black;South American'\n",
      " 'White;European;Hispanic or Latino/a;Multiracial;Biracial'\n",
      " 'White;European;North African' 'European;Biracial;Central Asian'\n",
      " 'Hispanic or Latino/a;Multiracial;Biracial'\n",
      " 'White;Indian;European;Asian;Black;Caribbean;South Asian;Multiracial'\n",
      " 'White;Middle Eastern;Ethnoreligious group;Hispanic or Latino/a;South American;Multiracial'\n",
      " 'White;European;Asian;East Asian;Southeast Asian;Multiracial;Biracial'\n",
      " 'White;North American;Asian;Southeast Asian;Multiracial'\n",
      " 'Indian;African;East Asian' 'Indian;Asian;Multiracial;Central Asian'\n",
      " 'European;Middle Eastern;Ethnoreligious group;Multiracial'\n",
      " 'Indian;Middle Eastern;Multiracial'\n",
      " 'White;Or, in your own words:;Asian;East Asian;Multiracial;Biracial'\n",
      " 'White;Central American;Hispanic or Latino/a;Multiracial'\n",
      " 'Black;South American;Biracial' 'South American;Multiracial;Biracial'\n",
      " 'White;Hispanic or Latino/a;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'European;North American;East Asian'\n",
      " 'White;European;Asian;Multiracial;Biracial'\n",
      " 'White;European;Asian;East Asian;Southeast Asian;South Asian;Multiracial;Biracial'\n",
      " 'White;North American;Asian;Southeast Asian;Multiracial;Biracial'\n",
      " 'European;Southeast Asian;Multiracial'\n",
      " 'Black;Hispanic or Latino/a;South American;Biracial'\n",
      " 'White;Caribbean;Hispanic or Latino/a;Multiracial'\n",
      " 'Indian;European;African;Black;Multiracial'\n",
      " 'White;European;North American;Hispanic or Latino/a'\n",
      " 'Indian;Asian;East Asian'\n",
      " 'East Asian;Hispanic or Latino/a;South American;Biracial'\n",
      " 'White;North American;Hispanic or Latino/a;Multiracial'\n",
      " 'European;Middle Eastern;Caribbean'\n",
      " 'Indian;North American;Hispanic or Latino/a'\n",
      " 'Black;Caribbean;Hispanic or Latino/a;South American'\n",
      " 'Asian;South American;Biracial' 'European;South American;Multiracial'\n",
      " 'White;European;East Asian;Biracial'\n",
      " 'White;European;African;Multiracial;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'White;European;North American;Black;Caribbean;Multiracial'\n",
      " 'Or, in your own words:;North American;Hispanic or Latino/a;Multiracial'\n",
      " 'North American;East Asian'\n",
      " 'White;Hispanic or Latino/a;South American;Indigenous (such as Native American or Indigenous Australian)'\n",
      " 'African;Black;Caribbean' 'White;Asian;South Asian;Multiracial'\n",
      " 'Or, in your own words:;Asian;Southeast Asian'\n",
      " 'Or, in your own words:;Middle Eastern;East Asian'\n",
      " 'Caribbean;South American;Multiracial' 'Asian;Hispanic or Latino/a'\n",
      " 'White;Middle Eastern;South American' 'Indian;East Asian'\n",
      " 'Or, in your own words:;European;Ethnoreligious group'\n",
      " 'White;North American;Asian;East Asian;Biracial'\n",
      " 'Or, in your own words:;Indian;South Asian'\n",
      " 'White;Indian;European;North American;Multiracial'\n",
      " 'White;European;North American;Middle Eastern;Asian;Multiracial']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Ethnicity' column\n",
    "print('Ethnicity: ', df['Ethnicity'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "50bfb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Ethnicity'] = pd.factorize(df['Ethnicity'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "db3d2706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessibility:  ['None of the above' 'I am deaf / hard of hearing' 'Prefer not to say'\n",
      " 'Or, in your own words:' 'I am blind / have difficulty seeing'\n",
      " 'I am deaf / hard of hearing;I am unable to / find it difficult to walk or stand without assistance'\n",
      " 'I am unable to / find it difficult to type'\n",
      " 'I am unable to / find it difficult to walk or stand without assistance'\n",
      " 'I am deaf / hard of hearing;I am blind / have difficulty seeing'\n",
      " 'Or, in your own words:;I am unable to / find it difficult to walk or stand without assistance'\n",
      " 'I am blind / have difficulty seeing;I am unable to / find it difficult to walk or stand without assistance'\n",
      " 'Or, in your own words:;I am deaf / hard of hearing'\n",
      " 'I am blind / have difficulty seeing;I am unable to / find it difficult to type'\n",
      " 'I am unable to / find it difficult to type;I am unable to / find it difficult to walk or stand without assistance'\n",
      " 'Or, in your own words:;I am blind / have difficulty seeing'\n",
      " 'I am deaf / hard of hearing;I am unable to / find it difficult to type'\n",
      " 'I am deaf / hard of hearing;I am blind / have difficulty seeing;I am unable to / find it difficult to type'\n",
      " 'Or, in your own words:;I am unable to / find it difficult to type'\n",
      " 'Or, in your own words:;I am blind / have difficulty seeing;I am unable to / find it difficult to type']\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'Accessibility' column\n",
    "print('Accessibility: ', df['Accessibility'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "32e91f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Accessibility'] = pd.factorize(df['Accessibility'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "737165e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MentalHealth:  ['I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.)'\n",
      " 'None of the above'\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder'\n",
      " 'I have an anxiety disorder'\n",
      " 'I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " 'Prefer not to say'\n",
      " \"I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have an anxiety disorder;I have a concentration and/or memory disorder (e.g., ADHD, etc.)'\n",
      " 'I have a concentration and/or memory disorder (e.g., ADHD, etc.)'\n",
      " \"I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.)'\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;I have a concentration and/or memory disorder (e.g., ADHD, etc.)'\n",
      " \"I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'Or, in your own words:'\n",
      " \"I have an anxiety disorder;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have a concentration and/or memory disorder (e.g., ADHD, etc.)'\n",
      " \"I have an anxiety disorder;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " \"Or, in your own words:;I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have an anxiety disorder;I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " 'I have an anxiety disorder;Or, in your own words:'\n",
      " 'I have an anxiety disorder;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " 'I have an anxiety disorder;I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);Or, in your own words:'\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);Or, in your own words:;I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " \"I have an anxiety disorder;I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;Or, in your own words:'\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);Or, in your own words:;I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"Or, in your own words:;I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.)'\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.)'\n",
      " 'Or, in your own words:;I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " \"Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have an anxiety disorder;Or, in your own words:;I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;Or, in your own words:;I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;I have learning differences (e.g., Dyslexic, Dyslexia, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"\n",
      " 'I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have learning differences (e.g., Dyslexic, Dyslexia, etc.)'\n",
      " 'I have an anxiety disorder;Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.)'\n",
      " \"I have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.);I have an anxiety disorder;Or, in your own words:;I have a concentration and/or memory disorder (e.g., ADHD, etc.);I have autism / an autism spectrum disorder (e.g. Asperger's, etc.)\"]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'MentalHealth' column\n",
    "print('MentalHealth: ', df['MentalHealth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f4c7fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'MentalHealth'] = pd.factorize(df['MentalHealth'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a8e58cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkExp:  [14.  5.  4. 23.  9. 22. 21.  6.  3. 28.  7.  8.  2. 20. 27. 10. 19.  1.\n",
      " 13. 30. 12. 15. 11. 17. 46. 25. 18. 24. 31.  0. 40. 16. 35. 32. 26. 36.\n",
      " 42. 38. 29. 33. 37. 34. 41. 44. 50. 45. 39. 43. 47. 48. 49.]\n"
     ]
    }
   ],
   "source": [
    "#let's display all unique values in 'WorkExp' column\n",
    "print('WorkExp: ', df['WorkExp'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e92fd9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's group all year of work experiece into 5 groups: less than 5 year, from 5 to 10, from 11 to 20, from 21 to 40 \n",
    "# and more than 40\n",
    "\n",
    "def process_age(age):\n",
    "    age = int(age)\n",
    "    age = int(age)\n",
    "    if age <5:\n",
    "        return(0)\n",
    "    elif (age >= 5 and age <=10):\n",
    "        return(1)\n",
    "    elif (age>10 and age <=20):\n",
    "        return (2)\n",
    "    elif (age>20 and age <=40):\n",
    "        return (3)\n",
    "    else:\n",
    "        return(4)\n",
    "\n",
    "# Apply the function to the column and create a new column\n",
    "df.loc[:,'WorkExp'] = df['WorkExp'].apply(process_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f170c02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>MainBranch</th>\n",
       "      <th>Employment</th>\n",
       "      <th>RemoteWork</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>Country</th>\n",
       "      <th>LanguageHaveWorkedWith</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Trans</th>\n",
       "      <th>Sexuality</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>WorkExp</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C#;HTML/CSS;JavaScript;PowerShell;Python;Rust;SQL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>194400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>C;HTML/CSS;Rust;SQL;Swift;TypeScript</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>HTML/CSS;JavaScript;PHP;Python;R;Ruby;Scala</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Python;SQL;TypeScript</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>C#;SQL;TypeScript</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>97605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73110</th>\n",
       "      <td>73111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>C#;HTML/CSS;JavaScript;TypeScript</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73112</th>\n",
       "      <td>73113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>HTML/CSS;Java;JavaScript</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73113</th>\n",
       "      <td>73114</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>C;C#;C++</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73116</th>\n",
       "      <td>73117</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>C#;HTML/CSS;Java;JavaScript</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73119</th>\n",
       "      <td>73120</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>C#;HTML/CSS;JavaScript;SQL;TypeScript</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24767 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ResponseId MainBranch Employment RemoteWork EdLevel YearsCode  \\\n",
       "11             12          1          1          1       1         3   \n",
       "12             13          2          2          2       1         3   \n",
       "14             15          2          1          1       2         3   \n",
       "21             22          2          2          2       2         2   \n",
       "22             23          2          2          1       3         4   \n",
       "...           ...        ...        ...        ...     ...       ...   \n",
       "73110       73111          2          2          1       1         3   \n",
       "73112       73113          2          2          2       1         2   \n",
       "73113       73114          2          2          1       2         2   \n",
       "73116       73117          2          2          2       1         4   \n",
       "73119       73120          2          2          2       1         2   \n",
       "\n",
       "      YearsCodePro OrgSize Country  \\\n",
       "11              10       1       1   \n",
       "12               5       2       1   \n",
       "14               5       3       1   \n",
       "21               4       1       2   \n",
       "22              20       4       3   \n",
       "...            ...     ...     ...   \n",
       "73110            9       1       3   \n",
       "73112            3       5      24   \n",
       "73113            5       5       1   \n",
       "73116           16       9       1   \n",
       "73119            1       3       1   \n",
       "\n",
       "                                  LanguageHaveWorkedWith Age Gender Trans  \\\n",
       "11     C#;HTML/CSS;JavaScript;PowerShell;Python;Rust;SQL   1      1     1   \n",
       "12                  C;HTML/CSS;Rust;SQL;Swift;TypeScript   2      1     1   \n",
       "14           HTML/CSS;JavaScript;PHP;Python;R;Ruby;Scala   2      1     1   \n",
       "21                                 Python;SQL;TypeScript   2      1     1   \n",
       "22                                     C#;SQL;TypeScript   1      1     1   \n",
       "...                                                  ...  ..    ...   ...   \n",
       "73110                  C#;HTML/CSS;JavaScript;TypeScript   2      2     1   \n",
       "73112                           HTML/CSS;Java;JavaScript   2      1     1   \n",
       "73113                                           C;C#;C++   2      1     1   \n",
       "73116                        C#;HTML/CSS;Java;JavaScript   1      1     1   \n",
       "73119              C#;HTML/CSS;JavaScript;SQL;TypeScript   2      1     1   \n",
       "\n",
       "      Sexuality Ethnicity Accessibility MentalHealth  WorkExp  \\\n",
       "11            1         1             1            1      2.0   \n",
       "12            1         1             1            2      1.0   \n",
       "14            1         1             1            2      1.0   \n",
       "21            1         2             1            2      0.0   \n",
       "22            1         3             1            2      3.0   \n",
       "...         ...       ...           ...          ...      ...   \n",
       "73110         1         3             1            2      1.0   \n",
       "73112         1         2             1            2      0.0   \n",
       "73113         1         1             1            9      1.0   \n",
       "73116         1         1             1            2      2.0   \n",
       "73119         1         1             4            9      1.0   \n",
       "\n",
       "       ConvertedCompYearly  \n",
       "11                194400.0  \n",
       "12                 65000.0  \n",
       "14                110000.0  \n",
       "21                 34126.0  \n",
       "22                 97605.0  \n",
       "...                    ...  \n",
       "73110              60906.0  \n",
       "73112              52255.0  \n",
       "73113              94000.0  \n",
       "73116             115000.0  \n",
       "73119              70000.0  \n",
       "\n",
       "[24767 rows x 19 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc6276",
   "metadata": {},
   "source": [
    "### the following 2 functions will make new columns with the names of all languages and write 1, if person knows this language and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5dbffdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that return 1 person knows each language in the list and 0 otherwise\n",
    "def process_list(lst):\n",
    "    languages = ['C#', 'C', 'HTML/CSS', 'Python' ,'Dart' ,'Bash/Shell' ,'JavaScript' ,'Java',\n",
    " 'Haskell', 'Assembly', 'Go', 'Groovy', 'Crystal' ,'PHP' ,'Delphi' ,'C++',\n",
    " 'Clojure' ,'Kotlin', 'APL', 'Rust' ,'TypeScript', 'COBOL' ,'PowerShell' ,'Scala',\n",
    " 'Elixir', 'F#' ,'LISP' ,'Ruby', 'Julia' ,'MATLAB', 'Objective-C' ,'Erlang',\n",
    " 'Swift', 'Fortran', 'OCaml' ,'R' ,'SQL', 'Perl' ,'Lua' ,'VBA']\n",
    "    result = \"\"\n",
    "    lst = lst.split(';')\n",
    "    for lang in languages:\n",
    "        if lang in lst:\n",
    "            result += \"1,\"\n",
    "        else:\n",
    "            result += \"0,\"\n",
    "    return result[:-1]  # Remove the trailing comma\n",
    "\n",
    "\n",
    "# Apply the function to the column and create a new column\n",
    "df.loc[:,'new_column'] = df['LanguageHaveWorkedWith'].apply(process_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4161d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add new colums with languges names\n",
    "\n",
    "\n",
    "# Specifying the column names\n",
    "column_names = ['C#', 'C', 'HTML/CSS', 'Python', 'Dart', 'Bash/Shell', 'JavaScript', 'Java',\n",
    "                'Haskell', 'Assembly', 'Go', 'Groovy', 'Crystal', 'PHP', 'Delphi', 'C++',\n",
    "                'Clojure', 'Kotlin', 'APL', 'Rust', 'TypeScript', 'COBOL', 'PowerShell',\n",
    "                'Scala', 'Elixir', 'F#', 'LISP', 'Ruby', 'Julia', 'MATLAB', 'Objective-C',\n",
    "                'Erlang', 'Swift', 'Fortran', 'OCaml', 'R', 'SQL', 'Perl', 'Lua', 'VBA']\n",
    "\n",
    "\n",
    "# Splitting the 'new_column' and assigning to the new DataFrame\n",
    "df[column_names] = df['new_column'].str.split(',', expand=True)\n",
    "\n",
    "df[column_names] = df[column_names].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "29da2d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>MainBranch</th>\n",
       "      <th>Employment</th>\n",
       "      <th>RemoteWork</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>Country</th>\n",
       "      <th>LanguageHaveWorkedWith</th>\n",
       "      <th>...</th>\n",
       "      <th>Objective-C</th>\n",
       "      <th>Erlang</th>\n",
       "      <th>Swift</th>\n",
       "      <th>Fortran</th>\n",
       "      <th>OCaml</th>\n",
       "      <th>R</th>\n",
       "      <th>SQL</th>\n",
       "      <th>Perl</th>\n",
       "      <th>Lua</th>\n",
       "      <th>VBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C#;HTML/CSS;JavaScript;PowerShell;Python;Rust;SQL</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>C;HTML/CSS;Rust;SQL;Swift;TypeScript</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>HTML/CSS;JavaScript;PHP;Python;R;Ruby;Scala</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Python;SQL;TypeScript</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>C#;SQL;TypeScript</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73110</th>\n",
       "      <td>73111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>C#;HTML/CSS;JavaScript;TypeScript</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73112</th>\n",
       "      <td>73113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>HTML/CSS;Java;JavaScript</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73113</th>\n",
       "      <td>73114</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>C;C#;C++</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73116</th>\n",
       "      <td>73117</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>C#;HTML/CSS;Java;JavaScript</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73119</th>\n",
       "      <td>73120</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>C#;HTML/CSS;JavaScript;SQL;TypeScript</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24767 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ResponseId MainBranch Employment RemoteWork EdLevel YearsCode  \\\n",
       "11             12          1          1          1       1         3   \n",
       "12             13          2          2          2       1         3   \n",
       "14             15          2          1          1       2         3   \n",
       "21             22          2          2          2       2         2   \n",
       "22             23          2          2          1       3         4   \n",
       "...           ...        ...        ...        ...     ...       ...   \n",
       "73110       73111          2          2          1       1         3   \n",
       "73112       73113          2          2          2       1         2   \n",
       "73113       73114          2          2          1       2         2   \n",
       "73116       73117          2          2          2       1         4   \n",
       "73119       73120          2          2          2       1         2   \n",
       "\n",
       "      YearsCodePro OrgSize Country  \\\n",
       "11              10       1       1   \n",
       "12               5       2       1   \n",
       "14               5       3       1   \n",
       "21               4       1       2   \n",
       "22              20       4       3   \n",
       "...            ...     ...     ...   \n",
       "73110            9       1       3   \n",
       "73112            3       5      24   \n",
       "73113            5       5       1   \n",
       "73116           16       9       1   \n",
       "73119            1       3       1   \n",
       "\n",
       "                                  LanguageHaveWorkedWith  ... Objective-C  \\\n",
       "11     C#;HTML/CSS;JavaScript;PowerShell;Python;Rust;SQL  ...           0   \n",
       "12                  C;HTML/CSS;Rust;SQL;Swift;TypeScript  ...           0   \n",
       "14           HTML/CSS;JavaScript;PHP;Python;R;Ruby;Scala  ...           0   \n",
       "21                                 Python;SQL;TypeScript  ...           0   \n",
       "22                                     C#;SQL;TypeScript  ...           0   \n",
       "...                                                  ...  ...         ...   \n",
       "73110                  C#;HTML/CSS;JavaScript;TypeScript  ...           0   \n",
       "73112                           HTML/CSS;Java;JavaScript  ...           0   \n",
       "73113                                           C;C#;C++  ...           0   \n",
       "73116                        C#;HTML/CSS;Java;JavaScript  ...           0   \n",
       "73119              C#;HTML/CSS;JavaScript;SQL;TypeScript  ...           0   \n",
       "\n",
       "      Erlang Swift Fortran OCaml  R SQL  Perl  Lua VBA  \n",
       "11         0     0       0     0  0   1     0    0   0  \n",
       "12         0     1       0     0  0   1     0    0   0  \n",
       "14         0     0       0     0  1   0     0    0   0  \n",
       "21         0     0       0     0  0   1     0    0   0  \n",
       "22         0     0       0     0  0   1     0    0   0  \n",
       "...      ...   ...     ...   ... ..  ..   ...  ...  ..  \n",
       "73110      0     0       0     0  0   0     0    0   0  \n",
       "73112      0     0       0     0  0   0     0    0   0  \n",
       "73113      0     0       0     0  0   0     0    0   0  \n",
       "73116      0     0       0     0  0   0     0    0   0  \n",
       "73119      0     0       0     0  0   1     0    0   0  \n",
       "\n",
       "[24767 rows x 60 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "204e003c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ResponseId, MainBranch, Employment, RemoteWork, EdLevel, YearsCode, YearsCodePro, OrgSize, Country, LanguageHaveWorkedWith, Age, Gender, Trans, Sexuality, Ethnicity, Accessibility, MentalHealth, WorkExp, ConvertedCompYearly, new_column, C#, C, HTML/CSS, Python, Dart, Bash/Shell, JavaScript, Java, Haskell, Assembly, Go, Groovy, Crystal, PHP, Delphi, C++, Clojure, Kotlin, APL, Rust, TypeScript, COBOL, PowerShell, Scala, Elixir, F#, LISP, Ruby, Julia, MATLAB, Objective-C, Erlang, Swift, Fortran, OCaml, R, SQL, Perl, Lua, VBA]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ba31c",
   "metadata": {},
   "source": [
    "### now let's drop unuseful columns again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0d092682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['LanguageHaveWorkedWith', 'new_column', 'YearsCodePro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fef7acdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>MainBranch</th>\n",
       "      <th>Employment</th>\n",
       "      <th>RemoteWork</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Objective-C</th>\n",
       "      <th>Erlang</th>\n",
       "      <th>Swift</th>\n",
       "      <th>Fortran</th>\n",
       "      <th>OCaml</th>\n",
       "      <th>R</th>\n",
       "      <th>SQL</th>\n",
       "      <th>Perl</th>\n",
       "      <th>Lua</th>\n",
       "      <th>VBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73110</th>\n",
       "      <td>73111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73112</th>\n",
       "      <td>73113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73113</th>\n",
       "      <td>73114</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73116</th>\n",
       "      <td>73117</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73119</th>\n",
       "      <td>73120</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24767 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ResponseId MainBranch Employment RemoteWork EdLevel YearsCode OrgSize  \\\n",
       "11             12          1          1          1       1         3       1   \n",
       "12             13          2          2          2       1         3       2   \n",
       "14             15          2          1          1       2         3       3   \n",
       "21             22          2          2          2       2         2       1   \n",
       "22             23          2          2          1       3         4       4   \n",
       "...           ...        ...        ...        ...     ...       ...     ...   \n",
       "73110       73111          2          2          1       1         3       1   \n",
       "73112       73113          2          2          2       1         2       5   \n",
       "73113       73114          2          2          1       2         2       5   \n",
       "73116       73117          2          2          2       1         4       9   \n",
       "73119       73120          2          2          2       1         2       3   \n",
       "\n",
       "      Country Age Gender  ... Objective-C Erlang Swift Fortran OCaml  R  SQL  \\\n",
       "11          1   1      1  ...           0      0     0       0     0  0    1   \n",
       "12          1   2      1  ...           0      0     1       0     0  0    1   \n",
       "14          1   2      1  ...           0      0     0       0     0  1    0   \n",
       "21          2   2      1  ...           0      0     0       0     0  0    1   \n",
       "22          3   1      1  ...           0      0     0       0     0  0    1   \n",
       "...       ...  ..    ...  ...         ...    ...   ...     ...   ... ..  ...   \n",
       "73110       3   2      2  ...           0      0     0       0     0  0    0   \n",
       "73112      24   2      1  ...           0      0     0       0     0  0    0   \n",
       "73113       1   2      1  ...           0      0     0       0     0  0    0   \n",
       "73116       1   1      1  ...           0      0     0       0     0  0    0   \n",
       "73119       1   2      1  ...           0      0     0       0     0  0    1   \n",
       "\n",
       "       Perl  Lua  VBA  \n",
       "11        0    0    0  \n",
       "12        0    0    0  \n",
       "14        0    0    0  \n",
       "21        0    0    0  \n",
       "22        0    0    0  \n",
       "...     ...  ...  ...  \n",
       "73110     0    0    0  \n",
       "73112     0    0    0  \n",
       "73113     0    0    0  \n",
       "73116     0    0    0  \n",
       "73119     0    0    0  \n",
       "\n",
       "[24767 rows x 57 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "586c4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cleaned data into new file \"CleanedData\"\n",
    "df1 = df\n",
    "df1.to_csv('CleanedData.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
